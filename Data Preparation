# Load necessary libraries
library(caret)
library(randomForest)
library(ggplot2)
library(dplyr)

# Load the data
training <- read.csv('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv', na.strings = c("NA", "#DIV/0!", ""))
testing <- read.csv('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv', na.strings = c("NA", "#DIV/0!", ""))

# Data cleaning
# Remove columns with more than 60% missing values
threshold <- 0.6
training <- training[, colSums(is.na(training)) / nrow(training) < threshold]
testing <- testing[, colSums(is.na(testing)) / nrow(testing) < threshold]

# Remove irrelevant columns
training <- training %>% select(-c(X, user_name, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp, new_window, num_window))
testing <- testing %>% select(-c(X, user_name, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp, new_window, num_window))

# Convert "classe" to a factor
training$classe <- as.factor(training$classe)

# Partition the training data into training and validation sets
set.seed(1234)
inTrain <- createDataPartition(training$classe, p = 0.7, list = FALSE)
training_set <- training[inTrain, ]
validation_set <- training[-inTrain, ]
